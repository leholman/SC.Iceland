seq(min(year), max(year))
interpol <- merge(data.frame("year"= seq(min(year), max(year))),data.frame("year" = year,"value"=value), by = "year", all = TRUE)
interpol$value <- na.approx(interpol$value,x=interpol$year,na.rm = FALSE)
interpol$value
valueSpline <- detrend.series(interpol$value,nyrs = 100,return.info=TRUE)
valueSpline <- detrend.series(interpol$value,nyrs = 50,return.info=TRUE)
plot(interpol$year,interpol$value,col="grey")
points(interpol$year,valueSpline$series$Spline,type="l",col="yellow",lwd=3)
valueSpline$series$Spline
### lets input data
climate <- read.csv("rawdata/climate/combined.csv")
sampledates <- read.csv("metadata/AgeOut.csv")
climatedat <- data.frame("Sample"=sampledates$ID,"Core"=sampledates$Core,"Date_bp_mean"=sampledates$mean,"Date_CE_mean"=1950-sampledates$mean)
unique(climate$record)
## Lets go!
## delta 13C
subset <- "Arcticad13C"
climate$record==subset
value <- climate$value[climate$record==subset]
year <- climate$year[climate$record==subset]
valueSpline <- detrend.series(value,nyrs = 100,return.info=TRUE)
plot(year,value,col="grey")
points(year,valueSpline$curves$Spline,type="l",col="yellow",lwd=3)
gam1 <- gam(value ~ s(year,k=50), method = "REML")
plot(gam1)
prediction <- data.frame("year"=953:2000)
prediction <- cbind(prediction,predict(gam1,newdata = prediction,se.fit = TRUE))
prediction$uppCI <- prediction$fit+prediction$se.fit*1.96
prediction$lwrCI <- prediction$fit-prediction$se.fit*1.96
prediction2 <- data.frame("year"=climatedat$Date_CE_mean)
prediction2$year[prediction2$year>max(year)|prediction2$year<min(year)] <- NA
prediction2 <- cbind(prediction2,predict(gam1,newdata = prediction2,se.fit = TRUE))
prediction2$uppCI <- prediction2$fit+prediction2$se.fit*1.96
prediction2$lwrCI <- prediction2$fit-prediction2$se.fit*1.96
prediction2$lowrezspline <- valueSpline$curves$Spline[match(prediction2$year,year)]
prediction$fit
points(year,prediction$fit,type="l")
pdf("figures/climate/Artica_d13C.pdf",height=6,width =11)
plot(climate$year[climate$record==subset],climate$value[climate$record==subset],pch=16,
xlab="YearCE",
ylab="Arctica d13C",
col="grey30")
polygon(c(prediction$year, rev(prediction$year)), c(prediction$uppCI, rev(prediction$lwrCI)), col=add.alpha('darkgreen',0.3), border=NA)
points(prediction$year,prediction$fit,lwd=3,col="darkgreen",type='l')
points(year,valueSpline$curves$Spline,type="l",col="yellow",lwd=3)
dev.off()
colnames(prediction2) <- c("year","d13C.GAM.fit","d13C.GAM.fit.se","d13C.GAM.fit.uppCI","d13C.GAM.fit.lwrCI","d13C.100yrspline")
climatedat <- cbind(climatedat,prediction2)
## delta 18O
subset <- "Arcticad18O"
climate$record==subset
value <- climate$value[climate$record==subset]
year <- climate$year[climate$record==subset]
valueSpline <- detrend.series(value,nyrs = 100,return.info=TRUE)
plot(year,value,col="grey")
points(year,valueSpline$curves$Spline,type="l",col="yellow",lwd=3)
gam1 <- gam(value ~ s(year,k=50), method = "REML")
plot(gam1)
prediction <- data.frame("year"=953:2000)
prediction <- cbind(prediction,predict(gam1,newdata = prediction,se.fit = TRUE))
prediction$uppCI <- prediction$fit+prediction$se.fit*1.96
prediction$lwrCI <- prediction$fit-prediction$se.fit*1.96
prediction2 <- data.frame("year"=climatedat$Date_CE_mean)
prediction2$year[prediction2$year>max(year)|prediction2$year<min(year)] <- NA
prediction2 <- cbind(prediction2,predict(gam1,newdata = prediction2,se.fit = TRUE))
prediction2$uppCI <- prediction2$fit+prediction2$se.fit*1.96
prediction2$lwrCI <- prediction2$fit-prediction2$se.fit*1.96
prediction2$lowrezspline <- valueSpline$curves$Spline[match(prediction2$year,year)]
pdf("figures/climate/Artica_d18O.pdf",height=6,width =11)
plot(climate$year[climate$record==subset],climate$value[climate$record==subset],pch=16,
xlab="YearCE",
ylab="Arctica d18O",
col="grey30")
polygon(c(prediction$year, rev(prediction$year)), c(prediction$uppCI, rev(prediction$lwrCI)), col=add.alpha('darkgreen',0.3), border=NA)
points(prediction$year,prediction$fit,lwd=3,col="darkgreen",type='l')
points(year,valueSpline$curves$Spline,type="l",col="yellow",lwd=3)
dev.off()
colnames(prediction2) <- c("year","d18O.GAM.fit","d18O.GAM.fit.se","d18O.GAM.fit.uppCI","d18O.GAM.fit.lwrCI","d18O.100yrspline")
climatedat <- cbind(climatedat,prediction2)
## Sea ice index
subset <- "SeaIceIndex"
climate$record==subset
value <- climate$value[climate$record==subset]
year <- climate$year[climate$record==subset]
valueSpline <- detrend.series(value,nyrs = 100,return.info=TRUE)
plot(year,value,col="grey")
points(year,valueSpline$curves$Spline,type="l",col="yellow",lwd=3)
gam1 <- gam(value ~ s(year,k=50), method = "REML")
plot(gam1)
max(year)
min(year)
prediction <- data.frame("year"=1600:2007)
prediction <- cbind(prediction,predict(gam1,newdata = prediction,se.fit = TRUE))
prediction$uppCI <- prediction$fit+prediction$se.fit*1.96
prediction$lwrCI <- prediction$fit-prediction$se.fit*1.96
prediction2 <- data.frame("year"=climatedat$Date_CE_mean)
prediction2$year[prediction2$year>max(year)|prediction2$year<min(year)] <- NA
prediction2 <- cbind(prediction2,predict(gam1,newdata = prediction2,se.fit = TRUE))
prediction2$uppCI <- prediction2$fit+prediction2$se.fit*1.96
prediction2$lwrCI <- prediction2$fit-prediction2$se.fit*1.96
pdf("figures/climate/SeaIceIndex.pdf",height=6,width =11)
plot(climate$year[climate$record==subset],climate$value[climate$record==subset],pch=16,
xlab="YearCE",
ylab="Seaice Index",
col="grey30")
polygon(c(prediction$year, rev(prediction$year)), c(prediction$uppCI, rev(prediction$lwrCI)), col=add.alpha('darkgreen',0.3), border=NA)
points(prediction$year,prediction$fit,lwd=3,col="darkgreen",type='l')
points(year,valueSpline$curves$Spline,type="l",col="yellow",lwd=3)
dev.off()
colnames(prediction2) <- c("year","SeaIceIndex.GAM.fit","SeaIceIndex.GAM.fit.se","SeaIceIndex.GAM.fit.uppCI","SeaIceIndex.GAM.fit.lwrCI","SeaIceIndex.100yrspline")
View(climatedat)
?write.csv
library("zoo")
write.csv(climatedat,"metadata/climate.csv")
climate <- read.csv("metadata/climate.csv")
View(climate)
climate <- read.csv("metadata/climate.csv",row.names = 1)
## here we use the average dataset
EUK.P19.MDS.b <- wcmdscale(vegdist(t(prop.table(EUK.P19.avr),2)),eig = TRUE)
####====0.1 Packages====####
library(vegan)
library(RColorBrewer)
library(breakaway)
library("mgcv")
library("Biostrings")
library("seqinr")
####====0.2 Functions====####
NrepsMaker <- function(INdataframe,vector){
##write these checks
#check the dataframe is a dataframe
if(!is.data.frame(INdataframe)){stop("Input dataframe doesn't look like a dataframe")}
#check the vector is a vector
if(!is.vector(vector)){stop("Input vector doesn't look like a vector")}
#check the dataframe contains the vector
## TO DO
#make a new dataframe to captuire the output
newDataFrame <- data.frame(matrix(0,nrow = length(INdataframe[,1]),ncol=length(unique(vector))))
#name stuff
colnames(newDataFrame) <- unique(vector)
rownames(newDataFrame) <- rownames(INdataframe)
#make it binary
INdataframe[INdataframe<1] <- 0
INdataframe[INdataframe>0] <- 1
#loop over all the samples with replicates, summing according to the vector
for (column in 1:length(newDataFrame[1,])){
# this if statement checks in case there is only one replicate remaining (this sometimes happens in controls)
if(is.vector(INdataframe[,vector %in% colnames(newDataFrame)[column]])){
newDataFrame[,column]  <- INdataframe[,vector %in% colnames(newDataFrame)[column]]}else{
newDataFrame[,column] <- rowSums(INdataframe[,vector %in% colnames(newDataFrame)[column]])}
}
return(newDataFrame)
}
CountTable <- function(in.taxonomy,in.data,output="Count",some.unassigned=T){
if(length(in.taxonomy)!=length(in.data[,1])){stop("Dataframe and corresponding taxonomy are not the same length")}
in.taxonomy[is.na(in.taxonomy)] <- ""
out.dat <- as.data.frame(matrix(ncol=length(in.data[1,]),nrow=length(unique(in.taxonomy))))
rownames(out.dat) <- sort(unique(in.taxonomy))
colnames(out.dat) <- colnames(in.data)
out.dat.abundance <- out.dat
for (sample in 1:length(in.data[1,])){
out.dat[,sample] <- table(in.taxonomy[in.data[,sample]>0])[match(sort(unique(in.taxonomy)),names(table(in.taxonomy[in.data[,sample]>0])))]
out.dat.abundance[,sample] <- aggregate(in.data[,sample], by=list(Category=in.taxonomy), FUN=sum)[,2]
}
out.dat[is.na(out.dat)] <- 0
if(some.unassigned==T){rownames(out.dat)[1] <- "Unassigned"}
if(output=="Count"){return(out.dat)}else if(
output=="Abundance"){return(out.dat.abundance)}
}
minAbundance <- function(inputtable = NA, minAbun = 0.01) {
others <- rep(0, ncol(inputtable))
for (col in 1:ncol(inputtable)) {
threshold = sum(inputtable[, col]) * minAbun
below_threshold_indices = inputtable[, col] < threshold
others[col] = sum(inputtable[below_threshold_indices, col])
inputtable[below_threshold_indices, col] = 0
}
inputtable <- rbind(inputtable, others)
rownames(inputtable)[nrow(inputtable)] = "Others"
# Remove rows that sum to zero
inputtable <- inputtable[rowSums(inputtable) != 0, ]
return(inputtable)
}
make_binary <- function (df,threshold){
df <- sapply(df, function(x) ifelse(is.numeric(x) & x < threshold, 0, 1))
return(as.data.frame(df))
}
average_by_reps <- function (df,sampleIndex){
# Check if the dataframe and cols have compatible sizes
if (ncol(df) != length(sampleIndex)) {
stop("The number of columns in the dataframe must match the length of the vector")
}
# Get unique sample names
unique_samples <- unique(sampleIndex)
# Initialize the output dataframe
avg_df <- data.frame(matrix(ncol = length(unique_samples), nrow = nrow(df)))
colnames(avg_df) <- unique_samples
# Compute averages for each sample
for (sample in unique_samples) {
indices <- which(sampleIndex == sample)  # Get indices for columns corresponding to this sample
if (length(indices) == 1) {
# If only one column, use it directly
avg_df[, sample] <- df[, indices, drop = FALSE]
} else {
# Compute row means for multiple columns
avg_df[, sample] <- rowMeans(df[, indices, drop = FALSE], na.rm = TRUE)
}
}
return(avg_df)
}
map_values_to_colors <- function(values, color1, color2) {
# Create a palette function with the two colors
palette <- colorRampPalette(c(color1, color2))
# Compute the number of unique values
num_colors <- length(unique(values))
# Generate the colors from the palette
colors <- palette(num_colors)
# Normalize the values to range from 1 to num_colors
scaled_values <- cut(values, breaks = pretty(range(values), num_colors), labels = FALSE)
# Assign colors based on scaled values
assigned_colors <- colors[scaled_values]
return(assigned_colors)
}
plot_with_gradient_legend <- function(values, color1, color2) {
# Use the mapping function to get assigned colors
assigned_colors <- map_values_to_colors(values, color1, color2)
# Define the gradient legend parameters
num_colors <- length(unique(values))
colors <- colorRampPalette(c(color1, color2))(num_colors)  # Recreate palette for the legend
legend_height <- (par("usr")[4] - par("usr")[3]) / 8  # 1/8 of the plot window height
legend_width <- 0.1 * (par("usr")[2] - par("usr")[1])  # Relative width of the legend
# Position of the legend at the bottom left
legend_x <- par("usr")[1] + 0.02 * (par("usr")[2] - par("usr")[1])  # Slightly offset from the left
legend_y <- par("usr")[3] + 0.02 * (par("usr")[4] - par("usr")[3])  # Slightly offset from the bottom
# Draw the gradient legend
for (i in 1:num_colors) {
rect_x <- legend_x
rect_y <- legend_y + (i-1) * (legend_height / num_colors)
rect(rect_x, rect_y, rect_x + legend_width, rect_y + (legend_height / num_colors), col = colors[i], border = NA)
}
# Labeling the min and max values at the bottom and top of the legend
text(legend_x + legend_width / 2, legend_y - 0.1 * legend_height, labels = min(values), cex = 0.8, adj = 0.5)
text(legend_x + legend_width / 2, legend_y + legend_height + 0.05 * legend_height, labels = max(values), cex = 0.8, adj = 0.5)
}
add.alpha <- function(col, alpha=1){
if(missing(col))
stop("Please provide a vector of colours.")
apply(sapply(col, col2rgb)/255, 2,
function(x)
rgb(x[1], x[2], x[3], alpha=alpha))
}
####====0.3 Data Prep====####
ages <- read.csv("metadata/AgeOut.csv")
ages$ID2 <- gsub("-","_",ages$ID)
EUK.tax.PR2 <- read.csv("taxonomy/EUK.cleaned.PR2.csv",row.names = 1)
climate <- read.csv("metadata/climate.csv",row.names = 1)
####====0.2 Functions====####
NrepsMaker <- function(INdataframe,vector){
##write these checks
#check the dataframe is a dataframe
if(!is.data.frame(INdataframe)){stop("Input dataframe doesn't look like a dataframe")}
#check the vector is a vector
if(!is.vector(vector)){stop("Input vector doesn't look like a vector")}
#check the dataframe contains the vector
## TO DO
#make a new dataframe to captuire the output
newDataFrame <- data.frame(matrix(0,nrow = length(INdataframe[,1]),ncol=length(unique(vector))))
#name stuff
colnames(newDataFrame) <- unique(vector)
rownames(newDataFrame) <- rownames(INdataframe)
#make it binary
INdataframe[INdataframe<1] <- 0
INdataframe[INdataframe>0] <- 1
#loop over all the samples with replicates, summing according to the vector
for (column in 1:length(newDataFrame[1,])){
# this if statement checks in case there is only one replicate remaining (this sometimes happens in controls)
if(is.vector(INdataframe[,vector %in% colnames(newDataFrame)[column]])){
newDataFrame[,column]  <- INdataframe[,vector %in% colnames(newDataFrame)[column]]}else{
newDataFrame[,column] <- rowSums(INdataframe[,vector %in% colnames(newDataFrame)[column]])}
}
return(newDataFrame)
}
CountTable <- function(in.taxonomy,in.data,output="Count",some.unassigned=T){
if(length(in.taxonomy)!=length(in.data[,1])){stop("Dataframe and corresponding taxonomy are not the same length")}
in.taxonomy[is.na(in.taxonomy)] <- ""
out.dat <- as.data.frame(matrix(ncol=length(in.data[1,]),nrow=length(unique(in.taxonomy))))
rownames(out.dat) <- sort(unique(in.taxonomy))
colnames(out.dat) <- colnames(in.data)
out.dat.abundance <- out.dat
for (sample in 1:length(in.data[1,])){
out.dat[,sample] <- table(in.taxonomy[in.data[,sample]>0])[match(sort(unique(in.taxonomy)),names(table(in.taxonomy[in.data[,sample]>0])))]
out.dat.abundance[,sample] <- aggregate(in.data[,sample], by=list(Category=in.taxonomy), FUN=sum)[,2]
}
out.dat[is.na(out.dat)] <- 0
if(some.unassigned==T){rownames(out.dat)[1] <- "Unassigned"}
if(output=="Count"){return(out.dat)}else if(
output=="Abundance"){return(out.dat.abundance)}
}
minAbundance <- function(inputtable = NA, minAbun = 0.01) {
others <- rep(0, ncol(inputtable))
for (col in 1:ncol(inputtable)) {
threshold = sum(inputtable[, col]) * minAbun
below_threshold_indices = inputtable[, col] < threshold
others[col] = sum(inputtable[below_threshold_indices, col])
inputtable[below_threshold_indices, col] = 0
}
inputtable <- rbind(inputtable, others)
rownames(inputtable)[nrow(inputtable)] = "Others"
# Remove rows that sum to zero
inputtable <- inputtable[rowSums(inputtable) != 0, ]
return(inputtable)
}
make_binary <- function (df,threshold){
df <- sapply(df, function(x) ifelse(is.numeric(x) & x < threshold, 0, 1))
return(as.data.frame(df))
}
average_by_reps <- function (df,sampleIndex){
# Check if the dataframe and cols have compatible sizes
if (ncol(df) != length(sampleIndex)) {
stop("The number of columns in the dataframe must match the length of the vector")
}
# Get unique sample names
unique_samples <- unique(sampleIndex)
# Initialize the output dataframe
avg_df <- data.frame(matrix(ncol = length(unique_samples), nrow = nrow(df)))
colnames(avg_df) <- unique_samples
# Compute averages for each sample
for (sample in unique_samples) {
indices <- which(sampleIndex == sample)  # Get indices for columns corresponding to this sample
if (length(indices) == 1) {
# If only one column, use it directly
avg_df[, sample] <- df[, indices, drop = FALSE]
} else {
# Compute row means for multiple columns
avg_df[, sample] <- rowMeans(df[, indices, drop = FALSE], na.rm = TRUE)
}
}
return(avg_df)
}
map_values_to_colors <- function(values, color1, color2) {
# Create a palette function with the two colors
palette <- colorRampPalette(c(color1, color2))
# Compute the number of unique values
num_colors <- length(unique(values))
# Generate the colors from the palette
colors <- palette(num_colors)
# Normalize the values to range from 1 to num_colors
scaled_values <- cut(values, breaks = pretty(range(values), num_colors), labels = FALSE)
# Assign colors based on scaled values
assigned_colors <- colors[scaled_values]
return(assigned_colors)
}
plot_with_gradient_legend <- function(values, color1, color2) {
# Use the mapping function to get assigned colors
assigned_colors <- map_values_to_colors(values, color1, color2)
# Define the gradient legend parameters
num_colors <- length(unique(values))
colors <- colorRampPalette(c(color1, color2))(num_colors)  # Recreate palette for the legend
legend_height <- (par("usr")[4] - par("usr")[3]) / 8  # 1/8 of the plot window height
legend_width <- 0.1 * (par("usr")[2] - par("usr")[1])  # Relative width of the legend
# Position of the legend at the bottom left
legend_x <- par("usr")[1] + 0.02 * (par("usr")[2] - par("usr")[1])  # Slightly offset from the left
legend_y <- par("usr")[3] + 0.02 * (par("usr")[4] - par("usr")[3])  # Slightly offset from the bottom
# Draw the gradient legend
for (i in 1:num_colors) {
rect_x <- legend_x
rect_y <- legend_y + (i-1) * (legend_height / num_colors)
rect(rect_x, rect_y, rect_x + legend_width, rect_y + (legend_height / num_colors), col = colors[i], border = NA)
}
# Labeling the min and max values at the bottom and top of the legend
text(legend_x + legend_width / 2, legend_y - 0.1 * legend_height, labels = min(values), cex = 0.8, adj = 0.5)
text(legend_x + legend_width / 2, legend_y + legend_height + 0.05 * legend_height, labels = max(values), cex = 0.8, adj = 0.5)
}
add.alpha <- function(col, alpha=1){
if(missing(col))
stop("Please provide a vector of colours.")
apply(sapply(col, col2rgb)/255, 2,
function(x)
rgb(x[1], x[2], x[3], alpha=alpha))
}
####====0.3 Data Prep====####
ages <- read.csv("metadata/AgeOut.csv")
ages$ID2 <- gsub("-","_",ages$ID)
EUK.tax.PR2 <- read.csv("taxonomy/EUK.cleaned.PR2.csv",row.names = 1)
climate <- read.csv("metadata/climate.csv",row.names = 1)
## EUK datasets
EUK.GC1 <- read.csv("cleaneddata/combinedcoredata/EUK.GC01.csv",row.names = 1)
EUK.GC1.nREPS <- NrepsMaker(EUK.GC1,gsub("(.*)_[0-9]$","\\1",colnames(EUK.GC1)))
EUK.GC1.avr <- average_by_reps(prop.table(as.matrix(EUK.GC1),2),gsub("(.*)_[0-9]$","\\1",colnames(EUK.GC1)))
EUK.GC1.bin <- make_binary(EUK.GC1,1)
EUK.GC1.ages <- ages$median[match(colnames(EUK.GC1.avr),ages$ID2)]
EUK.P19 <- read.csv("cleaneddata/combinedcoredata/EUK.PC019.csv",row.names = 1)
## make a subset of the data gettign rid of high resolution volcano samples
ages$ID2[184:204]
EUK.P19.nREPS <- NrepsMaker(EUK.P19,gsub("(.*)_[0-9]$","\\1",colnames(EUK.P19)))
EUK.P19.avr <- average_by_reps(prop.table(as.matrix(EUK.P19),2),gsub("(.*)_[0-9]$","\\1",colnames(EUK.P19)))
EUK.P19.bin <- make_binary(EUK.P19,1)
EUK.P19.ages <- ages$median[match(colnames(EUK.P19.avr),ages$ID2)]
### MAM datasets
MAM.P19 <- read.csv("cleaneddata/combinedcoredata/MAM.PC019.csv",row.names = 1)
MAM.P19.nREPS <- NrepsMaker(MAM.P19,gsub("(.*)_[0-9]$","\\1",colnames(MAM.P19)))
### RIZ datasets
RIZ.P19 <- read.csv("cleaneddata/combinedcoredata/RIZ.PC019.csv",row.names = 1)
RIZ.P19.nREPS <- NrepsMaker(RIZ.P19,gsub("(.*)_[0-9]$","\\1",colnames(RIZ.P19)))
###Make taxonomic files
MAMtax <- read.csv("taxonomy/MAM.combined.parsed.csv")
MAMasv <- readDNAStringSet("cleaneddata/ASVs/MAM.cleaned.fasta")
MAMtax$ASVseq <- as.character(MAMasv)[match(MAMtax$OTU,names(MAMasv))]
write.csv(MAMtax,file = "taxonomy/byHand/MAMtax.csv")
RIZtax <- read.csv("taxonomy/RIZ.combined.parsed.csv")
RIZasv <- readDNAStringSet("cleaneddata/ASVs/RIZ.cleaned.fasta")
RIZtax$ASVseq <- as.character(RIZasv)[match(RIZtax$OTU,names(RIZasv))]
write.csv(RIZtax,file = "taxonomy/byHand/RIZtax.csv")
## here we use the average dataset
EUK.P19.MDS.b <- wcmdscale(vegdist(t(prop.table(EUK.P19.avr),2)),eig = TRUE)
plot(EUK.P19.MDS.b)
## here we use the average dataset
EUK.P19.MDS.b <- wcmdscale(vegdist(t(prop.table(EUK.P19.avr,2))),eig = TRUE)
t(prop.table(EUK.P19.avr,2))
View(EUK.P19.avr)
colSums(EUK.P19.avr)
colnames((EUK.P19.avr))
gsub("(.*)_[0-9]$","\\1",colnames(EUK.P19.avr))
match(colnames(EUK.P19.avr),ages$ID2)
ages$median[match(colnames(EUK.P19.avr),ages$ID2)]
summary(climate)
ages$median[match(colnames(EUK.P19.avr),ages$ID2)]<1729
ages$median[match(colnames(EUK.P19.avr),ages$ID2)]<1729 & ages$median[match(colnames(EUK.P19.avr),ages$ID2)]>955
match(colnames(EUK.P19.avr),ages$ID2)<1729
ages$mean[match(colnames(EUK.P19.avr),ages$ID2)]<1729 & ages$mean[match(colnames(EUK.P19.avr),ages$ID2)]>955
ages$ID2[ages$mean[match(colnames(EUK.P19.avr),ages$ID2)]<1729 & ages$mean[match(colnames(EUK.P19.avr),ages$ID2)]>955]
ages$mean[match(colnames(EUK.P19.avr),ages$ID2)]<1729 & ages$mean[match(colnames(EUK.P19.avr),ages$ID2)]>955
ages$ID2[ages$mean[match(colnames(EUK.P19.avr),ages$ID2)]<1729 & ages$mean[match(colnames(EUK.P19.avr),ages$ID2)]>955]
table(ages$mean[match(colnames(EUK.P19.avr),ages$ID2)]<1729 & ages$mean[match(colnames(EUK.P19.avr),ages$ID2)]>955)
vector <- ages$mean[match(colnames(EUK.P19.avr),ages$ID2)]<1729 & ages$mean[match(colnames(EUK.P19.avr),ages$ID2)]>955
ages$ID2
match(colnames(EUK.P19.avr),ages$ID2)
colnames(EUK.P19.avr)[ages$mean[match(colnames(EUK.P19.avr),ages$ID2)]<1729 & ages$mean[match(colnames(EUK.P19.avr),ages$ID2)]>955]
colnames(EUK.P19.avr)
EUK.P19.avr[,ages$mean[match(colnames(EUK.P19.avr),ages$ID2)]<1729 & ages$mean[match(colnames(EUK.P19.avr),ages$ID2)]>955]
EUK.p19.avr.clim <- EUK.P19.avr[,ages$mean[match(colnames(EUK.P19.avr),ages$ID2)]<1729 & ages$mean[match(colnames(EUK.P19.avr),ages$ID2)]>955]
View(climate)
View(climate)
EUK.p19.avr.clim <- EUK.P19.avr[,ages$mean[match(colnames(EUK.P19.avr),ages$ID2)]<995 & ages$mean[match(colnames(EUK.P19.avr),ages$ID2)]>222]
View(EUK.p19.avr.clim)
colnames(EUK.p19.avr.clim)
climate$Core=="PC019"
PC019.climate <- climate[climate$Core=="PC019",]
PC019.climate$Sample
gsub("-","_",PC019.climate)
gsub("-","_",PC019.climate$Sample)
gsub("-","_",climate$Sample)
match(colnames(EUK.p19.avr.clim),gsub("-","_",climate$Sample))
PC019.climate <- climate[match(colnames(EUK.p19.avr.clim),gsub("-","_",climate$Sample)),]
PC019.climate
Pc019.dbRDA.j <- dbrda(vegdist(t(EUK.p19.avr.clim))~d13C.GAM.fit+d13C.100yrspline+d18O.GAM.fit+d18O.100yrspline,PC019.climate)
plot(Pc019.dbRDA.j)
summary(Pc019.dbRDA.j)
anova(Pc019.dbRDA.j)
?envfit()
test <- metaMDS(vegdist(t(EUK.p19.avr.clim)))
test <- metaMDS(vegdist(t(EUK.p19.avr.clim)),trymax = 200)
out.test <- envfit(test,PC019.climate)
out.test
plot(Pc019.dbRDA.j)
Pc019.dbRDA.j$Ybar
Pc019.dbRDA.j$terms
plot(test)
ordisurf(PC019.climate$d13C.GAM.fit)
?ordisurf
ordisurf(test,PC019.climate$d13C.GAM.fit)
Pc019.dbRDA.b <- dbrda(vegdist(t(EUK.p19.avr.clim),method="jaccard",binary = TRUE)~d13C.GAM.fit+d13C.100yrspline+d18O.GAM.fit+d18O.100yrspline,PC019.climate)
plot(Pc019.dbRDA.b)
anova(Pc019.dbRDA.b)
anova(Pc019.dbRDA.b,by="margin",permutations = 10000)
test <- metaMDS(vegdist(t(EUK.p19.avr.clim),method="jaccard",binary = TRUE),trymax = 200)
out.test <- envfit(test,PC019.climate)
plot(test)
ordisurf(test,PC019.climate$d13C.GAM.fit)
ordisurf(test,PC019.climate$d18O.GAM.fit)
ordisurf(test,PC019.climate$d18O.100yrspline)
View(PC019.climate)
View(climate)
test <- metaMDS(vegdist(t(EUK.p19.avr.clim),method="jaccard",binary = TRUE),trymax = 200)
out.test <- envfit(test,PC019.climate)
plot(Pc019.dbRDA.b)
anova(Pc019.dbRDA.b,by="margin",permutations = 10000)
Pc019.dbRDA.b <- dbrda(vegdist(t(EUK.p19.avr.clim))~d13C.GAM.fit+d13C.100yrspline+d18O.GAM.fit+d18O.100yrspline,PC019.climate)
Pc019.dbRDA.b <- dbrda(vegdist(t(EUK.p19.avr.clim))~d13C.GAM.fit+d13C.100yrspline+d18O.GAM.fit+d18O.100yrspline,PC019.climate)
Pc019.dbRDA.j <- dbrda(vegdist(t(EUK.p19.avr.clim),method="jaccard",binary = TRUE)~d13C.GAM.fit+d13C.100yrspline+d18O.GAM.fit+d18O.100yrspline,PC019.climate)
plot(Pc019.dbRDA.b)
plot(Pc019.dbRDA.j)
anova(Pc019.dbRDA.b,by="margin",permutations = 10000)
anova(Pc019.dbRDA.j,by="margin",permutations = 10000)
test <- metaMDS(vegdist(t(EUK.p19.avr.clim),method="jaccard",binary = TRUE),trymax = 200)
out.test <- envfit(test,PC019.climate)
plot(test)
ordisurf(test,PC019.climate$d18O.100yrspline)
test <- metaMDS(vegdist(t(EUK.p19.avr.clim)),trymax = 200)
out.test <- envfit(test,PC019.climate)
plot(test)
ordisurf(test,PC019.climate$d18O.100yrspline)
test <- metaMDS(vegdist(t(EUK.p19.avr.clim),method="jaccard",binary = TRUE),trymax = 200)
out.test <- envfit(test,PC019.climate)
plot(test)
ordisurf(test,PC019.climate$d18O.100yrspline)
test <- metaMDS(vegdist(t(EUK.p19.avr.clim),method="jaccard",binary = TRUE),trymax = 200)
out.test <- envfit(test,PC019.climate)
plot(test)
ordisurf(test,PC019.climate$d18O.100yrspline)
summary(PC019.climate$d18O.100yrspline)
plot(PC019.climate$d18O.100yrspline)
plot(PC019.climate$d13C.GAM.fit)
