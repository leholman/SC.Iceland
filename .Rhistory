cod$age <-  1950-age$mean[match(cod$X,gsub("-","_",age$ID))]
###parallel function to calcualte bootstraps
bootstrap_yearly_catch_parallel <- function(df, n_simulations = 10000) {
# Define confidence_levels *inside* the function
confidence_levels <- c("red" = 0.20, "amber" = 0.10, "green" = 0.05)
# Identify columns for each fishery
fishery_cols <- c("NorFish17_Iceland",
"NorFish18_Dutch",
"NorFish19_French",
"NorFish20_English")
num_cores <- parallel::detectCores() - 1
cl <- makeCluster(num_cores)
doParallel::registerDoParallel(cl)
results_matrix <- foreach(i = seq_len(n_simulations), .combine = rbind) %dopar% {
yearly_totals <- numeric(nrow(df))
for (j in seq_len(nrow(df))) {
total_catch <- 0
for (fishery in fishery_cols) {
conf_suffix <- gsub("NorFish[0-9]+_", "", fishery)
conf_col <- paste0("Conf_", conf_suffix)
catch_val <- df[[fishery]][j]
conf_val <- df[[conf_col]][j]
sd_percent <- confidence_levels[[conf_val]]
sampled_catch <- rnorm(1, mean = catch_val, sd = catch_val * sd_percent)
sampled_catch <- max(0, sampled_catch)
total_catch <- total_catch + sampled_catch
}
yearly_totals[j] <- total_catch
}
yearly_totals
}
stopCluster(cl)
colnames(results_matrix) <- df$Year
results_matrix
}
# --- Run the parallelized bootstrap ---
set.seed(123)
sim_results <- bootstrap_yearly_catch_parallel(fish_catch, n_simulations = 10000)
# Convert to a tidy data frame for plotting
df_plot <- as_tibble(sim_results) %>%
pivot_longer(
cols = everything(),
names_to = "Year",
values_to = "SimulatedCatch"
) %>%
group_by(Year) %>%
summarise(
mean_catch = mean(SimulatedCatch),
lower_95   = quantile(SimulatedCatch, 0.025),
upper_95   = quantile(SimulatedCatch, 0.975)
) %>%
mutate(Year = as.numeric(Year))
plot(df_plot$Year, df_plot$mean_catch, type = "l", col = "blue", lwd = 2,
xlab = "Year", ylab = "Catch", main = "Bootstrap Mean Catch with 95% CI",
ylim = range(df_plot$lower_95, df_plot$upper_95))
# Add shaded confidence interval
polygon(c(df_plot$Year, rev(df_plot$Year)),
c(df_plot$upper_95, rev(df_plot$lower_95)),
col = rgb(0, 0, 1, 0.3), border = NA)
points(fish_catch$Year,fish_catch$Sum,type="l",lwd=2,col="darkred")
####great now lets blur the signal to give a number that is a bit realistic
# Gaussian weighting function with edge correction
get_gaussian_weights <- function(window_size = 10, actual_size = NULL) {
x <- seq(-window_size, window_size, length.out = 2 * window_size-1)  # Properly symmetric window
weights <- dnorm(x, mean = 0, sd = window_size / 2)  # Normal distribution weights
# If the window is smaller than expected (at dataset edges)
if (!is.null(actual_size)) {
center_idx <- ceiling(length(weights) / 2)  # Center index
half_size <- floor(actual_size / 2)  # How much to take from each side
start_idx <- max(1, center_idx - half_size)  # Avoid going below index 1
end_idx <- min(length(weights), center_idx + half_size)  # Avoid exceeding length
weights <- weights[start_idx:end_idx]  # Take a **centered** subset
}
weights <- weights / sum(weights)  # Normalize so weights sum to 1
return(weights)
}
# Parallel bootstrap with moving average smoothing (corrected edges)
bootstrap_yearly_catch_parallel_blurred <- function(df, n_simulations = 10000) {
confidence_levels <- c("red" = 0.50, "amber" = 0.10, "green" = 0.05)
fishery_cols <- c("NorFish17_Iceland",
"NorFish18_Dutch",
"NorFish19_French",
"NorFish20_English")
num_cores <- min(detectCores() - 1, 8)  # Limit cores for stability
cl <- makeCluster(num_cores)
registerDoParallel(cl)
results_matrix <- tryCatch({
foreach(i = seq_len(n_simulations), .combine = rbind,
.export = c("get_gaussian_weights")) %dopar% {
yearly_totals <- numeric(nrow(df))
for (j in seq_len(nrow(df))) {
total_catch <- 0
for (fishery in fishery_cols) {
conf_suffix <- gsub("NorFish[0-9]+_", "", fishery)
conf_col <- paste0("Conf_", conf_suffix)
catch_val <- df[[fishery]][j]
conf_val <- df[[conf_col]][j]
sd_percent <- confidence_levels[[conf_val]]
sampled_catch <- rnorm(1, mean = catch_val, sd = catch_val * sd_percent)
sampled_catch <- max(0, sampled_catch)
total_catch <- total_catch + sampled_catch
}
yearly_totals[j] <- total_catch
}
# Apply Gaussian-weighted moving average smoothing with edge handling
smoothed_totals <- yearly_totals
for (j in seq_len(nrow(df))) {
# Determine valid range for this window
min_idx <- max(1, j - 5)
max_idx <- min(nrow(df), j + 5)
actual_size <- max_idx - min_idx + 1  # Actual number of valid years in window
weights <- get_gaussian_weights(10, actual_size)  # Adjust weights safely
smoothed_totals[j] <- sum(yearly_totals[min_idx:max_idx] * weights)
}
smoothed_totals
}
}, finally = {
stopCluster(cl)  # Ensure cluster shuts down
})
colnames(results_matrix) <- df$Year
results_matrix
}
# Run the modified parallel bootstrap with edge handling
set.seed(123)
sim_results_blurred <- bootstrap_yearly_catch_parallel_blurred(fish_catch, n_simulations = 10000)
# Convert to a tidy data frame for plotting
df_plot <- as_tibble(sim_results_blurred ) %>%
pivot_longer(
cols = everything(),
names_to = "Year",
values_to = "SimulatedCatch"
) %>%
group_by(Year) %>%
summarise(
mean_catch = mean(SimulatedCatch),
lower_95   = quantile(SimulatedCatch, 0.025),
upper_95   = quantile(SimulatedCatch, 0.975)
) %>%
mutate(Year = as.numeric(Year))
plot(df_plot$Year, df_plot$mean_catch, type = "l", col = "blue", lwd = 2,
xlab = "Year", ylab = "Catch", main = "Bootstrap Mean Catch with 95% CI",
ylim = range(12000, df_plot$upper_95),xlim = c(1500,1875))
# Add shaded confidence interval
polygon(c(df_plot$Year, rev(df_plot$Year)),
c(df_plot$upper_95, rev(df_plot$lower_95)),
col = rgb(0, 0, 1, 0.3), border = NA)
plot(df_plot$Year, df_plot$mean_catch, type = "l", col = "blue", lwd = 2,
xlab = "Year", ylab = "Catch (Metric Tonnes)", main = "Bootstrap Mean Catch with 95% CI",
ylim = range(12000, df_plot$upper_95),xlim = c(1500,1875))
# Add shaded confidence interval
polygon(c(df_plot$Year, rev(df_plot$Year)),
c(df_plot$upper_95, rev(df_plot$lower_95)),
col = rgb(0, 0, 1, 0.3), border = NA)
plot(df_plot$Year, df_plot$mean_catch, type = "l", col = "blue", lwd = 2,
xlab = "Year", ylab = "Catch (Metric Tonnes)", main = "",
ylim = range(12000, df_plot$upper_95),xlim = c(1500,1875))
# Add shaded confidence interval
polygon(c(df_plot$Year, rev(df_plot$Year)),
c(df_plot$upper_95, rev(df_plot$lower_95)),
col = rgb(0, 0, 1, 0.3), border = NA)
####====0.1 Packages====####
library(vegan)
library(RColorBrewer)
library(breakaway)
library("mgcv")
library("Biostrings")
library("seqinr")
####====0.2 Functions====####
NrepsMaker <- function(INdataframe,vector){
##write these checks
#check the dataframe is a dataframe
if(!is.data.frame(INdataframe)){stop("Input dataframe doesn't look like a dataframe")}
#check the vector is a vector
if(!is.vector(vector)){stop("Input vector doesn't look like a vector")}
#check the dataframe contains the vector
## TO DO
#make a new dataframe to captuire the output
newDataFrame <- data.frame(matrix(0,nrow = length(INdataframe[,1]),ncol=length(unique(vector))))
#name stuff
colnames(newDataFrame) <- unique(vector)
rownames(newDataFrame) <- rownames(INdataframe)
#make it binary
INdataframe[INdataframe<1] <- 0
INdataframe[INdataframe>0] <- 1
#loop over all the samples with replicates, summing according to the vector
for (column in 1:length(newDataFrame[1,])){
# this if statement checks in case there is only one replicate remaining (this sometimes happens in controls)
if(is.vector(INdataframe[,vector %in% colnames(newDataFrame)[column]])){
newDataFrame[,column]  <- INdataframe[,vector %in% colnames(newDataFrame)[column]]}else{
newDataFrame[,column] <- rowSums(INdataframe[,vector %in% colnames(newDataFrame)[column]])}
}
return(newDataFrame)
}
CountTable <- function(in.taxonomy,in.data,output="Count",some.unassigned=T){
if(length(in.taxonomy)!=length(in.data[,1])){stop("Dataframe and corresponding taxonomy are not the same length")}
in.taxonomy[is.na(in.taxonomy)] <- ""
out.dat <- as.data.frame(matrix(ncol=length(in.data[1,]),nrow=length(unique(in.taxonomy))))
rownames(out.dat) <- sort(unique(in.taxonomy))
colnames(out.dat) <- colnames(in.data)
out.dat.abundance <- out.dat
for (sample in 1:length(in.data[1,])){
out.dat[,sample] <- table(in.taxonomy[in.data[,sample]>0])[match(sort(unique(in.taxonomy)),names(table(in.taxonomy[in.data[,sample]>0])))]
out.dat.abundance[,sample] <- aggregate(in.data[,sample], by=list(Category=in.taxonomy), FUN=sum)[,2]
}
out.dat[is.na(out.dat)] <- 0
if(some.unassigned==T){rownames(out.dat)[1] <- "Unassigned"}
if(output=="Count"){return(out.dat)}else if(
output=="Abundance"){return(out.dat.abundance)}
}
minAbundance <- function(inputtable = NA, minAbun = 0.01) {
others <- rep(0, ncol(inputtable))
for (col in 1:ncol(inputtable)) {
threshold = sum(inputtable[, col]) * minAbun
below_threshold_indices = inputtable[, col] < threshold
others[col] = sum(inputtable[below_threshold_indices, col])
inputtable[below_threshold_indices, col] = 0
}
inputtable <- rbind(inputtable, others)
rownames(inputtable)[nrow(inputtable)] = "Others"
# Remove rows that sum to zero
inputtable <- inputtable[rowSums(inputtable) != 0, ]
return(inputtable)
}
make_binary <- function (df,threshold){
df <- sapply(df, function(x) ifelse(is.numeric(x) & x < threshold, 0, 1))
return(as.data.frame(df))
}
average_by_reps <- function (df,sampleIndex){
# Check if the dataframe and cols have compatible sizes
if (ncol(df) != length(sampleIndex)) {
stop("The number of columns in the dataframe must match the length of the vector")
}
# Get unique sample names
unique_samples <- unique(sampleIndex)
# Initialize the output dataframe
avg_df <- data.frame(matrix(ncol = length(unique_samples), nrow = nrow(df)))
colnames(avg_df) <- unique_samples
# Compute averages for each sample
for (sample in unique_samples) {
indices <- which(sampleIndex == sample)  # Get indices for columns corresponding to this sample
if (length(indices) == 1) {
# If only one column, use it directly
avg_df[, sample] <- df[, indices, drop = FALSE]
} else {
# Compute row means for multiple columns
avg_df[, sample] <- rowMeans(df[, indices, drop = FALSE], na.rm = TRUE)
}
}
return(avg_df)
}
map_values_to_colors <- function(values, color1, color2) {
# Create a palette function with the two colors
palette <- colorRampPalette(c(color1, color2))
# Compute the number of unique values
num_colors <- length(unique(values))
# Generate the colors from the palette
colors <- palette(num_colors)
# Normalize the values to range from 1 to num_colors
scaled_values <- cut(values, breaks = pretty(range(values), num_colors), labels = FALSE)
# Assign colors based on scaled values
assigned_colors <- colors[scaled_values]
return(assigned_colors)
}
plot_with_gradient_legend <- function(values, color1, color2) {
# Use the mapping function to get assigned colors
assigned_colors <- map_values_to_colors(values, color1, color2)
# Define the gradient legend parameters
num_colors <- length(unique(values))
colors <- colorRampPalette(c(color1, color2))(num_colors)  # Recreate palette for the legend
legend_height <- (par("usr")[4] - par("usr")[3]) / 8  # 1/8 of the plot window height
legend_width <- 0.1 * (par("usr")[2] - par("usr")[1])  # Relative width of the legend
# Position of the legend at the bottom left
legend_x <- par("usr")[1] + 0.02 * (par("usr")[2] - par("usr")[1])  # Slightly offset from the left
legend_y <- par("usr")[3] + 0.02 * (par("usr")[4] - par("usr")[3])  # Slightly offset from the bottom
# Draw the gradient legend
for (i in 1:num_colors) {
rect_x <- legend_x
rect_y <- legend_y + (i-1) * (legend_height / num_colors)
rect(rect_x, rect_y, rect_x + legend_width, rect_y + (legend_height / num_colors), col = colors[i], border = NA)
}
# Labeling the min and max values at the bottom and top of the legend
text(legend_x + legend_width / 2, legend_y - 0.1 * legend_height, labels = min(values), cex = 0.8, adj = 0.5)
text(legend_x + legend_width / 2, legend_y + legend_height + 0.05 * legend_height, labels = max(values), cex = 0.8, adj = 0.5)
}
add.alpha <- function(col, alpha=1){
if(missing(col))
stop("Please provide a vector of colours.")
apply(sapply(col, col2rgb)/255, 2,
function(x)
rgb(x[1], x[2], x[3], alpha=alpha))
}
# Here is a function to create labels from dates in numeric form such that +ive numbers give CE and -ive numbers give BCE
number_to_CE_label <- function(numbers) {
# Create an empty character vector to store the labels
labels <- character(length(numbers))
# Loop through each number in the vector
for (i in seq_along(numbers)) {
if (numbers[i] >= 0) {
labels[i] <- paste(numbers[i], "CE")
} else {
labels[i] <- paste(abs(numbers[i]), "BCE")
}
}
return(labels)
}
####====0.3 Data Prep====####
ages <- read.csv("metadata/AgeOut.csv")
ages$ID2 <- gsub("-","_",ages$ID)
EUK.tax.PR2 <- read.csv("taxonomy/EUK.cleaned.PR2.csv",row.names = 1)
EUK.tax.PR2.cat <- read.csv("taxonomy/functionalAnno/EUK.cleaned.PR2.cat.csv",row.names = 1)
climate <- read.csv("metadata/climate.csv",row.names = 1)
## EUK datasets
EUK.GC1 <- read.csv("cleaneddata/combinedcoredata/EUK.GC01.csv",row.names = 1)
EUK.GC1.nREPS <- NrepsMaker(EUK.GC1,gsub("(.*)_[0-9]$","\\1",colnames(EUK.GC1)))
EUK.GC1.avr <- average_by_reps(prop.table(as.matrix(EUK.GC1),2),gsub("(.*)_[0-9]$","\\1",colnames(EUK.GC1)))
EUK.GC1.bin <- make_binary(EUK.GC1,1)
EUK.GC1.ages <- ages$mean[match(colnames(EUK.GC1.avr),ages$ID2)]
EUK.P19 <- read.csv("cleaneddata/combinedcoredata/EUK.PC019.csv",row.names = 1)
EUK.P19.nREPS <- NrepsMaker(EUK.P19,gsub("(.*)_[0-9]$","\\1",colnames(EUK.P19)))
EUK.P19.avr <- average_by_reps(prop.table(as.matrix(EUK.P19),2),gsub("(.*)_[0-9]$","\\1",colnames(EUK.P19)))
EUK.P19.bin <- make_binary(EUK.P19,1)
EUK.P19.ages <- ages$mean[match(colnames(EUK.P19.avr),ages$ID2)]
#make subsets per taxonomic group
##P19
EUK.p19.avr.bac <- EUK.P19.avr[match(EUK.tax.PR2$X.1[EUK.tax.PR2$Domain=="Bacteria" & EUK.tax.PR2$Domain.1>80],EUK.tax.PR2$X.1),]
row.names(EUK.p19.avr.bac) <- EUK.tax.PR2$X.1[EUK.tax.PR2$Domain=="Bacteria" & EUK.tax.PR2$Domain.1>80]
EUK.p19.avr.met <- EUK.P19.avr[match(na.omit(EUK.tax.PR2$X.1[EUK.tax.PR2$Subdivision=="Metazoa" & EUK.tax.PR2$Subdivision>80]),EUK.tax.PR2$X.1),]
row.names(EUK.p19.avr.met) <- na.omit(EUK.tax.PR2$X.1[EUK.tax.PR2$Subdivision=="Metazoa" & EUK.tax.PR2$Subdivision>80])
EUK.p19.avr.pro <- EUK.P19.avr[match(na.omit(EUK.tax.PR2$X.1[EUK.tax.PR2$Domain!="Bacteria" & EUK.tax.PR2$Subdivision!="Metazoa" & EUK.tax.PR2$Subdivision!="Fungi" & EUK.tax.PR2$Subdivision>80]),EUK.tax.PR2$X.1),]
row.names(EUK.p19.avr.pro) <- na.omit(EUK.tax.PR2$X.1[EUK.tax.PR2$Domain!="Bacteria" & EUK.tax.PR2$Subdivision!="Metazoa" & EUK.tax.PR2$Subdivision!="Fungi" & EUK.tax.PR2$Subdivision>80])
#GC1
EUK.GC1.avr.bac <- EUK.GC1.avr[match(EUK.tax.PR2$X.1[EUK.tax.PR2$Domain=="Bacteria" & EUK.tax.PR2$Domain.1>80],EUK.tax.PR2$X.1),]
row.names(EUK.GC1.avr.bac) <- EUK.tax.PR2$X.1[EUK.tax.PR2$Domain=="Bacteria" & EUK.tax.PR2$Domain.1>80]
EUK.GC1.avr.met <- EUK.GC1.avr[match(na.omit(EUK.tax.PR2$X.1[EUK.tax.PR2$Subdivision=="Metazoa" & EUK.tax.PR2$Subdivision>80]),EUK.tax.PR2$X.1),]
row.names(EUK.GC1.avr.met) <- na.omit(EUK.tax.PR2$X.1[EUK.tax.PR2$Subdivision=="Metazoa" & EUK.tax.PR2$Subdivision>80])
EUK.GC1.avr.pro <- EUK.GC1.avr[match(na.omit(EUK.tax.PR2$X.1[EUK.tax.PR2$Domain!="Bacteria" & EUK.tax.PR2$Subdivision!="Metazoa" & EUK.tax.PR2$Subdivision!="Fungi" & EUK.tax.PR2$Subdivision>80]),EUK.tax.PR2$X.1),]
row.names(EUK.GC1.avr.pro) <- na.omit(EUK.tax.PR2$X.1[EUK.tax.PR2$Domain!="Bacteria" & EUK.tax.PR2$Subdivision!="Metazoa" & EUK.tax.PR2$Subdivision!="Fungi" & EUK.tax.PR2$Subdivision>80])
###Make taxonomic files
EUKtax <- read.csv("taxonomy/EUK.combined.parsed.csv")
EUKasv <- readDNAStringSet("cleaneddata/ASVs/EUK.cleaned.fasta")
EUKtax$ASVseq <- as.character(EUKasv)[match(EUKtax$OTU,names(EUKasv))]
write.csv(EUKtax,file = "taxonomy/byHand/EUKtax.csv")
####====1.0 Taxonomic overview====####
getPalette = colorRampPalette(brewer.pal(9, "Set3"))
#GC1
EUK.GC1.tax.a <- minAbundance(CountTable(as.character(EUK.tax.PR2$Family),EUK.GC1.avr,output = "Abundance"),minAbun=0.01)
EUK.GC1.tax.c <- minAbundance(CountTable(as.character(EUK.tax.PR2$Family),EUK.GC1.avr,output = "Count"),minAbun=0.01)
row.names(EUK.GC1.tax.a)[1] <- "Unknown"
row.names(EUK.GC1.tax.c)[1] <- "Unknown"
EUK.GC1.tax.a <- as.matrix(prop.table(as.matrix(EUK.GC1.tax.a[,order(ages$mean[match(colnames(EUK.GC1.tax.a),ages$ID2)])]),margin = 2))
EUK.GC1.tax.c <- as.matrix(prop.table(as.matrix(EUK.GC1.tax.c[,order(ages$mean[match(colnames(EUK.GC1.tax.c),ages$ID2)])]),margin = 2))
barplot(EUK.GC1.tax.a,col=rev(getPalette(dim(EUK.GC1.tax.a)[1])))
barplot(EUK.GC1.tax.c,col=rev(getPalette(dim(EUK.GC1.tax.c)[1])))
pdf("figures/fig1/EUK.GC1.tax.Family.pdf",width = 12,height = 9)
par(mfrow=c(2,1),mar=c(5.1, 4.1, 1.1, 6.1),xpd=TRUE)
barplot(EUK.GC1.tax.a,las=2,cex.names=0.6,col=rev(getPalette(dim(EUK.GC1.tax.a)[1])),ylab="Read Abundance",names.arg=ages$mean[match(colnames(EUK.GC1.tax.a),ages$ID2)])
legend(56,1,rev(rownames(EUK.GC1.tax.a)),fill=getPalette(dim(EUK.GC1.tax.a)[1]),cex=0.5,bty = "n",y.intersp=0.75)
barplot(EUK.GC1.tax.c,las=2,cex.names=0.6,col=rev(getPalette(dim(EUK.GC1.tax.c)[1])),ylab="ASV Counts",names.arg=ages$mean[match(colnames(EUK.GC1.tax.c),ages$ID2)])
legend(56,1,rev(rownames(EUK.GC1.tax.c)),fill=getPalette(dim(EUK.GC1.tax.c)[1]),cex=0.5,bty = "n",y.intersp=0.75)
dev.off()
#GC1 cat
EUK.GC1.tax.a <- minAbundance(CountTable(as.character(EUK.tax.PR2.cat$cat),EUK.GC1.avr,output = "Abundance"),minAbun=0.01)
EUK.GC1.tax.c <- minAbundance(CountTable(as.character(EUK.tax.PR2.cat$cat),EUK.GC1.avr,output = "Count"),minAbun=0.01)
EUK.GC1.tax.a <- as.matrix(prop.table(as.matrix(EUK.GC1.tax.a[,order(ages$mean[match(colnames(EUK.GC1.tax.a),ages$ID2)])]),margin = 2))
EUK.GC1.tax.c <- as.matrix(prop.table(as.matrix(EUK.GC1.tax.c[,order(ages$mean[match(colnames(EUK.GC1.tax.c),ages$ID2)])]),margin = 2))
barplot(EUK.GC1.tax.a,col=rev(getPalette(dim(EUK.GC1.tax.a)[1])))
barplot(EUK.GC1.tax.c,col=rev(getPalette(dim(EUK.GC1.tax.c)[1])))
pdf("figures/fig1/EUK.GC1.tax.cat.pdf",width = 12,height = 9)
par(mfrow=c(2,1),mar=c(5.1, 4.1, 1.1, 6.1),xpd=TRUE)
barplot(EUK.GC1.tax.a,las=2,cex.names=0.6,col=rev(getPalette(dim(EUK.GC1.tax.a)[1])),ylab="Read Abundance",names.arg=ages$mean[match(colnames(EUK.GC1.tax.a),ages$ID2)])
legend(56,1,rev(rownames(EUK.GC1.tax.a)),fill=getPalette(dim(EUK.GC1.tax.a)[1]),cex=0.5,bty = "n",y.intersp=0.75)
barplot(EUK.GC1.tax.c,las=2,cex.names=0.6,col=rev(getPalette(dim(EUK.GC1.tax.c)[1])),ylab="ASV Counts",names.arg=ages$mean[match(colnames(EUK.GC1.tax.c),ages$ID2)])
legend(56,1,rev(rownames(EUK.GC1.tax.c)),fill=getPalette(dim(EUK.GC1.tax.c)[1]),cex=0.5,bty = "n",y.intersp=0.75)
dev.off()
##PC19
EUK.P19.tax.a <- minAbundance(CountTable(as.character(EUK.tax.PR2$Family),EUK.P19.avr,output = "Abundance"),minAbun=0.01)
EUK.P19.tax.c <- minAbundance(CountTable(as.character(EUK.tax.PR2$Family),EUK.P19.avr,output = "Count"),minAbun=0.01)
row.names(EUK.P19.tax.a)[1] <- "Unknown"
row.names(EUK.P19.tax.c)[1] <- "Unknown"
EUK.P19.tax.a <- as.matrix(prop.table(as.matrix(EUK.P19.tax.a[,order(ages$mean[match(colnames(EUK.P19.tax.a),ages$ID2)])]),margin = 2))
EUK.P19.tax.c <- as.matrix(prop.table(as.matrix(EUK.P19.tax.c[,order(ages$mean[match(colnames(EUK.P19.tax.c),ages$ID2)])]),margin = 2))
pdf("figures/EUK.P19.tax.Family.pdf",width = 12,height = 9)
par(mfrow=c(2,1),mar=c(5.1, 4.1, 1.1, 6.1),xpd=TRUE)
barplot(EUK.P19.tax.a,las=2,cex.names=0.6,col=rev(getPalette(dim(EUK.P19.tax.a)[1])),ylab="Read Abundance",names.arg=ages$mean[match(colnames(EUK.P19.tax.a),ages$ID2)])
legend(190,1,rev(rownames(EUK.P19.tax.a)),fill=getPalette(dim(EUK.P19.tax.a)[1]),cex=0.5,bty = "n",y.intersp=0.75)
barplot(EUK.P19.tax.c,las=2,cex.names=0.6,col=rev(getPalette(dim(EUK.P19.tax.c)[1])),ylab="ASV Counts",names.arg=ages$mean[match(colnames(EUK.P19.tax.c),ages$ID2)])
legend(190,1,rev(rownames(EUK.P19.tax.c)),fill=getPalette(dim(EUK.P19.tax.c)[1]),cex=0.5,bty = "n",y.intersp=0.75)
dev.off()
##PC19 cat
EUK.P19.tax.a <- minAbundance(CountTable(as.character(EUK.tax.PR2.cat$cat),EUK.P19.avr,output = "Abundance"),minAbun=0.01)
EUK.P19.tax.c <- minAbundance(CountTable(as.character(EUK.tax.PR2.cat$cat),EUK.P19.avr,output = "Count"),minAbun=0.01)
EUK.P19.tax.a <- as.matrix(prop.table(as.matrix(EUK.P19.tax.a[,order(ages$mean[match(colnames(EUK.P19.tax.a),ages$ID2)])]),margin = 2))
EUK.P19.tax.c <- as.matrix(prop.table(as.matrix(EUK.P19.tax.c[,order(ages$mean[match(colnames(EUK.P19.tax.c),ages$ID2)])]),margin = 2))
pdf("figures/EUK.P19.tax.cat.pdf",width = 12,height = 9)
par(mfrow=c(2,1),mar=c(5.1, 4.1, 1.1, 6.1),xpd=TRUE)
barplot(EUK.P19.tax.a,las=2,cex.names=0.6,col=rev(getPalette(dim(EUK.P19.tax.a)[1])),ylab="Read Abundance",names.arg=1950-ages$mean[match(colnames(EUK.P19.tax.a),ages$ID2)])
legend(190,1,rev(rownames(EUK.P19.tax.a)),fill=getPalette(dim(EUK.P19.tax.a)[1]),cex=0.5,bty = "n",y.intersp=0.75)
barplot(EUK.P19.tax.c,las=2,cex.names=0.6,col=rev(getPalette(dim(EUK.P19.tax.c)[1])),ylab="ASV Counts",names.arg=1950-ages$mean[match(colnames(EUK.P19.tax.c),ages$ID2)])
legend(190,1,rev(rownames(EUK.P19.tax.c)),fill=getPalette(dim(EUK.P19.tax.c)[1]),cex=0.5,bty = "n",y.intersp=0.75)
dev.off()
#Both
unique_taxa <- sort(unique(c(rownames(EUK.P19.tax.a), rownames(EUK.GC1.tax.a))))
taxa_colors <- setNames(colorRampPalette(brewer.pal(12, "Set1"))(length(unique_taxa)), unique_taxa)
EUK.P19.tax.a <- EUK.P19.tax.a[order(rownames(EUK.P19.tax.a)),]
EUK.GC1.tax.a <- EUK.GC1.tax.a[order(rownames(EUK.GC1.tax.a)),]
pdf("figures/EUK.tax.cat.pdf",width = 12,height = 9)
par(mfrow=c(2,1),mar=c(5.1, 4.1, 1.1, 6.1),xpd=TRUE)
barplot(EUK.P19.tax.a[,dim(EUK.P19.tax.a)[2]:1],las=2,cex.names=0.6,col=taxa_colors[rownames(EUK.P19.tax.a)],ylab="Read Abundance",border = NA,ylim=c(1,0),yaxt="n",
names.arg=number_to_CE_label(rev(1950-ages$mean[match(colnames(EUK.P19.tax.a),ages$ID2)])))
axis(2,at=seq(0,1,.2),labels=rev(seq(0,1,.2)),las=2)
#legend(190,0.2,unique_taxa,fill=taxa_colors[unique_taxa],cex=0.5,bty = "n",y.intersp=0.75, xpd = TRUE,inset = c(-0.25, 0))
barplot(EUK.GC1.tax.a[,dim(EUK.GC1.tax.a)[2]:1],las=2,cex.names=0.6,col=taxa_colors[rownames(EUK.GC1.tax.a)],ylab="Read Abundance",border = NA,ylim=c(1,0),yaxt="n",
names.arg=number_to_CE_label(rev(1950-ages$mean[match(colnames(EUK.GC1.tax.a),ages$ID2)])))
axis(2,at=seq(0,1,.2),labels=rev(seq(0,1,.2)),las=2)
par(mfrow=c(1, 1))
legend(57,0.3,unique_taxa,col=taxa_colors[unique_taxa],cex=0.7,pch=15,pt.cex = 2,bty = "n", xpd = TRUE)
dev.off()
pdf("figures/EUK.tax.cat.big.pdf",width = 22,height = 11)
par(mfrow=c(2,1),mar=c(5.1, 4.1, 1.1, 6.1),xpd=TRUE)
barplot(EUK.P19.tax.a[,dim(EUK.P19.tax.a)[2]:1],las=2,cex.names=0.6,col=taxa_colors[rownames(EUK.P19.tax.a)],ylab="Read Abundance",border = NA,ylim=c(1,0),yaxt="n",
names.arg=number_to_CE_label(rev(1950-ages$mean[match(colnames(EUK.P19.tax.a),ages$ID2)])))
axis(2,at=seq(0,1,.2),labels=rev(seq(0,1,.2)),las=2)
#legend(190,0.2,unique_taxa,fill=taxa_colors[unique_taxa],cex=0.5,bty = "n",y.intersp=0.75, xpd = TRUE,inset = c(-0.25, 0))
barplot(EUK.GC1.tax.a[,dim(EUK.GC1.tax.a)[2]:1],las=2,cex.names=0.6,col=taxa_colors[rownames(EUK.GC1.tax.a)],ylab="Read Abundance",border = NA,ylim=c(1,0),yaxt="n",
names.arg=number_to_CE_label(rev(1950-ages$mean[match(colnames(EUK.GC1.tax.a),ages$ID2)])))
axis(2,at=seq(0,1,.2),labels=rev(seq(0,1,.2)),las=2)
par(mfrow=c(1, 1))
legend(57,0.3,unique_taxa,col=taxa_colors[unique_taxa],cex=0.7,pch=15,pt.cex = 2,bty = "n", xpd = TRUE)
dev.off()
pdf("figures/fig1/EUK.tax.cat.blank.pdf",width = 12,height = 9)
par(mfrow=c(2,1),mar=c(5.1, 4.1, 1.1, 7.1),xpd=TRUE)
barplot(EUK.P19.tax.a[,dim(EUK.P19.tax.a)[2]:1],las=2,col=taxa_colors[rownames(EUK.P19.tax.a)],ylab="Relative Abundance",border = NA,ylim=c(1,0),yaxt="n",xaxt = "n")
axis(2,at=seq(0,1,.2),labels=rev(seq(0,1,.2)),las=2,)
barplot(EUK.GC1.tax.a[,dim(EUK.GC1.tax.a)[2]:1],las=2,col=taxa_colors[rownames(EUK.GC1.tax.a)],ylab="Relative Abundance",border = NA,ylim=c(1,0),yaxt="n",xaxt = "n")
axis(2,at=seq(0,1,.2),labels=rev(seq(0,1,.2)),las=2)
par(mfrow=c(1, 1))
legend(57,0.3,unique_taxa,col=taxa_colors[unique_taxa],cex=0.8,pch=15,pt.cex = 2,bty = "n", xpd = TRUE)
dev.off()
## now how about some subsets
## we need a couple of functions here
move_unknown_last_vector <- function(vec) {
if (!"Unknown" %in% vec) {
warning("No 'Unknown' value found in the vector.")
return(vec)
}
c(setdiff(vec, "Unknown"), "Unknown")
}
move_unknown_last <- function(mat) {0
if (!"Unknown" %in% rownames(mat)) {
warning("No 'Unknown' row found in the matrix.")
return(mat)
}
mat[c(setdiff(rownames(mat), "Unknown"), "Unknown"), , drop = FALSE]
}
######### Protist basic plot
EUK.tax.PR2.pro <-  EUK.tax.PR2[match(rownames(EUK.p19.avr.pro),EUK.tax.PR2$X.1),]
EUK.P19.tax.pro.a <-   as.matrix(minAbundance(CountTable(gsub("_X","",as.character(EUK.tax.PR2.pro$Subdivision)),EUK.p19.avr.pro,output = "Abundance"),minAbun=0.01))
EUK.GC1.tax.pro.a <-   as.matrix(minAbundance(CountTable(gsub("_X","",as.character(EUK.tax.PR2.pro$Subdivision)),EUK.GC1.avr.pro,output = "Abundance"),minAbun=0.01))
row.names(EUK.P19.tax.pro.a)[1] <- "Unknown"
row.names(EUK.GC1.tax.pro.a)[1] <- "Unknown"
EUK.P19.tax.pro.a <- EUK.P19.tax.pro.a[order(rownames(EUK.P19.tax.pro.a)),]
EUK.GC1.tax.pro.a <- EUK.GC1.tax.pro.a[order(rownames(EUK.GC1.tax.pro.a)),]
EUK.P19.tax.pro.a <- EUK.P19.tax.pro.a[,order(ages$mean[match(colnames(EUK.P19.tax.pro.a),ages$ID2)])]
EUK.GC1.tax.pro.a <- EUK.GC1.tax.pro.a[,order(ages$mean[match(colnames(EUK.GC1.tax.pro.a),ages$ID2)])]
# Move unknown
EUK.P19.tax.met.a <- move_unknown_last(EUK.P19.tax.met.a)
### lets make some fish plots
EUKtax.h <- read.csv("taxonomy/byHand/EUKtax_assigned1006.csv")
## lets do one of EUK cod first
taxa <- "Gadus"
loopASVs <- EUKtax.h$OTU[EUKtax.h$Assignment==taxa]
test1 <- EUK.P19[loopASVs,]
View(test1)
test1 <- EUK.P19[loopASVs,]
test2 <- EUK.GC1[loopASVs,]
View(test1)
hist(colSums(EUK.P19),breaks = 100)
hist(colSums(test1))
hist(colSums(test1),breaks=100)
hist(colSums(test2))
hist(colSums(test2),breaks=100)
taxa <- "Clupea"
test1 <- EUK.P19[loopASVs,]
test2 <- EUK.GC1[loopASVs,]
View(EUKtax.h)
test2
View(test1)
taxa
test1.clupea <- EUK.P19[loopASVs,]
test2.clupea <- EUK.GC1[loopASVs,]
## lets do one of EUK cod first
taxa <- "Gadus"
## lets do one of EUK cod first
taxa <- "Clupea"
loopASVs <- EUKtax.h$OTU[EUKtax.h$Assignment==taxa]
test1.clupea <- EUK.P19[loopASVs,]
test2.clupea <- EUK.GC1[loopASVs,]
View(test1.clupea)
clupea <- EUK.P19[loopASVs,],EUK.GC1[loopASVs,]
clupea <- cbind(EUK.P19[loopASVs,],EUK.GC1[loopASVs,])
View(clupea)
colSums(cbind(EUK.P19,EUK.GC1))
clupea2 <- rbind(clupea,colSums(cbind(EUK.P19,EUK.GC1)))
View(clupea2)
write.csv(clupea2,"Clupea.csv")
## lets do one of EUK cod first
taxa <- "Gadus"
loopASVs <- EUKtax.h$OTU[EUKtax.h$Assignment==taxa]
clupea <- cbind(EUK.P19[loopASVs,],EUK.GC1[loopASVs,])
clupea2 <- rbind(clupea,colSums(cbind(EUK.P19,EUK.GC1)))
View(clupea2)
write.csv(clupea2,"Gadus.csv")
